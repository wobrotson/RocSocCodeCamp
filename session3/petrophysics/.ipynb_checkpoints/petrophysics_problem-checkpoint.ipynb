{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling petrophysical well log data in Python\n",
    "**Author**: Aline Melo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: Import well log data and create a new lithology curve log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The well log we will use is part of the test datasets available on the Quantitative Seismic Interpretation book website:\n",
    "\n",
    "https://srb.stanford.edu/quantitative-seismic-interpretation\n",
    "\n",
    "We will use \"Well 2\", contained in the \"Project Data\" zipfile (`qsiwell2.csv`).\n",
    "\n",
    "__Objective:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "#Note the use of the Pandas library to digest log data\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Loading and getting to know your data with Pandas\n",
    "\n",
    "Let's load `qsiwell2.csv` into the [Pandas DataFrame](http://pandas.pydata.org/pandas-docs/dev/dsintro.html#dataframe) `L`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=pd.read_csv('qsiwell2.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check what's now inside `L`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have all the required logs for a quantitative analysis: <br>\n",
    "- 'VP' = compressional velocity <br>\n",
    "- 'VS' = shear velocity <br>\n",
    "- 'RHO_OLD' = density <br>\n",
    "- 'GR' = gamma-ray <br>\n",
    "- 'NPHI' = neutron porosity <br>\n",
    "- 'RHO' = density <br>\n",
    "- 'SWE' = effective water saturation <br>\n",
    "- 'SWX' = water saturation <br>\n",
    "- 'VPVS' = Vp/Vs ratio <br>\n",
    "- 'IP' = P-wave impedance <br>\n",
    "- 'IS' = S-wave impedance <br>\n",
    "- 'VSH' = shale volume <br>\n",
    "- 'RHOm' = (tool) corrected density <br>\n",
    "- 'RHOf' = fluid densit <br>\n",
    "- 'PHIE' = effective porosity <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logs stored into a Pandas DataFrame, here `L`, are easily accessed using the syntax `DataFrame['log']`, e.g. `L['VP']` is the P-wave velocity and `L['PHIE']` is effective porosity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average RHO:')\n",
    "print(L['RHO'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To select more than one log, use the syntax `DataFrame[['log1','log2']]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average RHO:')\n",
    "print(L[['RHO','VP']].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we imported the data we defined an index column `index_col=0`.\n",
    "\n",
    "Now we can mix and match with filters such as `DataFrame.index>2100` to restrict the data only to those values below 2100 m and you can get all the information you need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average RHO above 2100 m:')\n",
    "print(L[(L.index<=2100)]['RHO'].mean())\n",
    "\n",
    "print('Average RHO below 2100 m:')\n",
    "print(L[(L.index>=2100)]['RHO'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1:\n",
    "\n",
    "Print average Vp and RHO between 1500 and 2000 m:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average Ip between 1500 and 2000 m:')\n",
    "\n",
    "# write your code here:\n",
    "# print(L[\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove a specific log (e.g., that RHO_OLD) we can use the drop method with the optional axis=1 (required otherwise Pandas will search for a row named RHO_OLD instead of a column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=L.drop(['RHO_OLD'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:\n",
    "Check if `RHO_OLD` has been deleted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "# L.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:\n",
    "Rename the column `RHOf` to `RHOfluid`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "#L.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4:\n",
    "Rename all multiple columns in one go and check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "# L.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is great to manage large and complex datasets; the basic Dataframe is a compact, portable and powerful data structure that allows you to quickly inspect your data, either using standard Python functions (like min(), .max(), .mean()) or the describe method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now rename back to the original names and check for the next tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "# L.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5:\n",
    "Use the describe function on the DataFrame `L` for the columns `VP, VS, RHO, and PHIE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "# L[[]].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Create a lithology classification based on the data\n",
    "\n",
    "Now we will calculate a column named Litho-Fluid Class (LFC) that groups data identified by similar lithological and/or pore fluid content. The identification of the groups will be based on the values of the logs.\n",
    "\n",
    "The LFC log will have four classes:\n",
    "\n",
    "- LFC=0: undef\n",
    "- LFC=1: brine sand\n",
    "- LFC=2: oil sand\n",
    "- LFC=4: shale\n",
    "\n",
    "The classification will be based on the shale volume (VSH) and water saturation (SWE). The rules for each class are:\n",
    "\n",
    "- LFC=0: undef <br>\n",
    "Parts that are outside the ranges defined\n",
    "\n",
    "\n",
    "- LFC=1: brine sand (ssb) <br>\n",
    "Parts that have less than 20% of shale volume and more than 90% of water saturation\n",
    "\n",
    "\n",
    "- LFC=2: oil sand (sso) <br>\n",
    "Parts that have less than 20% of shale volume and less than 90% of water saturation\n",
    "\n",
    "\n",
    "- LFC=4: shale (sh) <br>\n",
    "Parts that have more than 20% of shale volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first check if the file with the measurements has empy cells: <br>\n",
    "`np.where(pd.isnull(df))` returns the row and column indices where the value is NaN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(pd.isnull(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are regions that the petrophysical logs were not computed. <br>\n",
    "For this reason, we will focus on a smaller depth window with data between 2100 and 2400 m."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redefine the DataFrame `L` as being `L` only between 2100 and 2400 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the blanks below:\n",
    "#L=L[()&()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check if this interval has empty cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "#np.w...(pd....())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the `LFC` log, we will create \"flag\" logs to help us identify the right intervals that correspond to each class.\n",
    "\n",
    "We will create the flag logs `ssb`, `sso`, and `sh` (i.e., logs made of samples that can only be 1 or 0, i.e. _True_ or *False*) using cut-off values on `VSH` (shale volume) and `SW` (water saturation).\n",
    "\n",
    "Implement in the cell bellow the rules for each flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "#sand_cutoff=\n",
    "#watersat_cutoff=\n",
    "#ssb=\n",
    "#sso=\n",
    "#sh=\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to use the above flags to create the `LFC` log and store it into`L` with the other logs. <br>\n",
    "First we will create a temporary variable and allocate memory to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "#temp_lfc=np....(np.....())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to make this temporary variable equals to:\n",
    "- 1 when ssb (brine sand flag) is True\n",
    "- 2 when sso (oil sand flag) is True\n",
    "- 3 when sh (shale flag) is True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "#temp_lf[]=\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now insert the new column to our spreadsheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.insert(L.columns.size, 'LFC', temp_lfc) # the first argument is the position, in this way LFC will be the last one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see if this is all ok; the total number of samples after zooming in the 2100-2400 m depth window is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(L.VSH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many cells are there for each facies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "#print('brine sst={}, oil sst={}, shale={}'.format(np...,np...,np....))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 11:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a final check to make this newly defined LFC log only has values within the range 1 to 3 (there will be no undefined samples in this particular depth interval, i.e. classes with `LFC=0`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here:\n",
    "#print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very easy to do plots of all types with Pandas, and to show that here's a one-liner that plots Vp histograms for each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.VP.hist(bins=50, color='black', by=L.LFC, figsize=(12,2), layout=(1,3), lw=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final task: summary plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need a custom colormap for my classes, i.e. a discrete colormap with following classes-colors association:\n",
    "\n",
    "- LFC=0: undef, GRAY\n",
    "- LFC=1: brine sand, BLUE\n",
    "- LFC=2: oil sand, RED\n",
    "- LFC=3: shale, GREEN\n",
    "\n",
    "This is the way to define this colormap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember we imported matplotlib.colors as colors\n",
    "\n",
    "ccc = ['#B3B3B3','blue','red','green']\n",
    "cmap_facies = colors.ListedColormap(ccc[0:len(ccc)], 'indexed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now display a summary view of all the logs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 12:\n",
    "Implement the missing parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we first create variable ll to help us plotting the results without changing our original spreadsheet\n",
    "ztop=2100; zbot=2400\n",
    "ll=L[(L.index>=ztop) & (L.index<=zbot)]\n",
    "\n",
    "# We now expand the LFC to look nice in the plot\n",
    "cluster=np.repeat(np.expand_dims(ll['LFC'].values,1),100,1)\n",
    "\n",
    "# Here we create a plot with 4 subplots:\n",
    "f, ax = plt.subplots(nrows=1, ncols=4, figsize=(8, 6))\n",
    "\n",
    "# The first subplot will display three curves, the first on is the volume of shale (VSH) in green:\n",
    "ax[0].plot(ll.VSH, ll.index, '-g', label='Vsh')\n",
    "\n",
    "# The second is the water saturation (SWE) in blue:\n",
    "#ax[0].plot()\n",
    "\n",
    "# The third is the porosity (PHIE) in black:\n",
    "#ax[0].plot()\n",
    "\n",
    "# The second subplot will display the P-wave impedance (IP) in gray 50%:\n",
    "#ax[1].plot()\n",
    "\n",
    "# The third subplot will display the Vp/Vp ratio (VPVS) in gray 50%:\n",
    "#ax[2].plot()\n",
    "\n",
    "# The fourth subplot will display the LFC log we created:\n",
    "im=ax[3].imshow(cluster, interpolation='none', aspect='auto',cmap=cmap_facies,vmin=0,vmax=4)\n",
    "cbar=plt.colorbar(im, ax=ax[3])\n",
    "cbar.set_label((12*' ').join(['undef', 'brine', 'oil', 'shale']))\n",
    "cbar.set_ticks(range(0,1)); cbar.set_ticklabels('')\n",
    "\n",
    "# Because we want the depth from the lowest to the highest values, we will invert the y axis:\n",
    "for i in ax[:-1]:\n",
    "    i.set_ylim(ztop,zbot)\n",
    "    i.invert_yaxis()\n",
    "    i.grid()\n",
    "    i.locator_params(axis='x', nbins=4)\n",
    "\n",
    "# We will define the limits for each plot based on the statistics of the variables to avoid emply spaces in the plot:    \n",
    "ax[0].set_xlim(-.1,1.1)\n",
    "ax[1].set_xlim(3000,9000)\n",
    "ax[2].set_xlim(1.5,3)\n",
    "\n",
    "# We can now add a nice legend:\n",
    "ax[0].legend(fontsize='small', loc='lower right')\n",
    "ax[0].set_xlabel('Vcl/phi/Sw')\n",
    "ax[1].set_xlabel('Ip [m/s*g/cc]')\n",
    "ax[2].set_xlabel('Vp/Vs')    \n",
    "ax[3].set_xlabel('LFC')\n",
    "\n",
    "# And labels for the depth:\n",
    "ax[1].set_yticklabels([]); ax[2].set_yticklabels([]); ax[3].set_yticklabels([]); ax[3].set_xticklabels([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the same data in crossplot domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(L.IP,L.VPVS,20,L.LFC,marker='o',edgecolors='none',alpha=0.7,cmap=cmap_facies,vmin=0,vmax=4)\n",
    "plt.xlim(3000,9000); plt.ylim(1.5,3); plt.grid(); plt.xlabel('Ip'); plt.ylabel('Vp/Vs')\n",
    "cbar=plt.colorbar()\n",
    "cbar.set_label((15*' ').join(['undef', 'brine', 'oil', 'shale']))\n",
    "cbar.set_ticks(range(0,1)); cbar.set_ticklabels('')\n",
    "#-----------------------------------------------------------------\n",
    "#-- alternative way to label the colorbar:\n",
    "#cbar.set_label('0=undef,1=brine,2=oil,3=shale')\n",
    "#cbar.set_ticks(range(0,4+1)); cbar.set_ticklabels(range(0,4+1));\n",
    "#-----------------------------------------------------------------\n",
    "cbar.set_alpha(1)\n",
    "cbar.draw_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
