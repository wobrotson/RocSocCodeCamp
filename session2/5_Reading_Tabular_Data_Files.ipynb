{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2\n",
    "In this Session 2, we will take a sample earth science dataset, visualise it, analyse and interpret it and transform it into a publishable result.\n",
    "\n",
    "## The Earth Science dataset\n",
    "\n",
    "The dataset we are using for this exercise are a number of quantitative measurements on bedding-parallel carbonate veins in a thinly layered mudstone to siltstone sequence in Zambia. These veins were formed during burial diagenesis in the Neoproterozoic from fluid overpressures in what is essentially a reservoir seal unit. The dataset we will read into Python consists of measurements on individual transects perpendicular to the trend of the veins.\n",
    "\n",
    "\n",
    "<img src=\"../images/s2_vein_transect_example.png\" alt=\"Variable\" width=\"600\"/>\n",
    "<center> <i> Two vein transects with veins of variable thickness indicated in black </i> </center>\n",
    "\n",
    "#### The data files\n",
    "\n",
    "The dataset is captured as a tabulated datafile in *.csv* format. Each row in the datafile contains the info on a single vein along the transect. Each row or line in the datafile contains two values: \n",
    "* The position along the transect of the centre of vein [in mm]\n",
    "* The spacing between the centre of a vein and the centre of a previous vein along the transect [in mm]\n",
    "* The thickness of that vein [in mm]\n",
    "\n",
    "Often, the individual values in each row in tables or tabular data are delimited by either whitespace or characters (space, tabs, comma, semicolon, ...) with each row. \n",
    "\n",
    "## Reading the datafiles\n",
    "The first step is to read the datafile into Python. For this we will use a package called Pandas. In many programming languages including Python, libraries and packages are developed for a specific purpose, which we can 'import' and use within our code, without having to embed the code within those packages in our scripts. \n",
    "\n",
    "#### Introduction to Pandas\n",
    "\n",
    "Pandas is an open source package providing high-performance data structures and analysis tools for Python. It provides a Python equivalent of the data analysis and manipulation tools available in the R programming language. It is a great package for manipulating and analysing tabular data and time series.\n",
    "\n",
    "Pandas offers two key data structures that are optimised for data analysis and manipulation: **Series** and **Data Frame**. The key distinction of these data structures over basic Python data structures is that they *make it easy to associate an index with data - i.e. row and column names.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, we import the Pandas package. We can import it as *pd* for shorthand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Data Frames\n",
    "A Pandas Data Frame is a 2-dimensional labelled data structure with columns of data that can be of different types. It supports both position-based and index-based data access. This means you can query and manipulate values using the position of a given cell or cell range in the table, or you can use the index *('headers')* of the table to do so.\n",
    "\n",
    "read_csv is a function of the pandas package (which we imported as *pd*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('Vein_dataset_small.csv')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of showing the entire table, we can use a function called `head()` on our Dataframe `dataframe`, which simply returns the first few rows (*header*) of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask to return just the column with the name \"Position\", similar to how we would ask to return a value in a list: `dataframe[\"name\"]` or `listname[3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[\"Position\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can ask to return two columns of our choosing. Here we use: `dataframe[[list of column names]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[[\"Thickness\", \"Spacing\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select a subset of rows of two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[2:7][[\"Thickness\",\"Spacing\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next notebook\n",
    "\n",
    "In the next notebook we will analyse and plot the data within the datafile we just read in.\n",
    "\n",
    "[Click here to open the next notebook](6_Analysing_Data.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
